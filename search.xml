<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[论文略读（一）]]></title>
    <url>%2F2021%2F01%2F22%2F%E8%AE%BA%E6%96%87%E7%95%A5%E8%AF%BB%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[DiCENet: Dimension-wise convolutions for efficient networks主题文章提出了一种分维度卷积之后维度特征融合的一种新模块，相对于经典的深度可分离模块（典型网络为MobileNet、ShuffleNet）来说性能更好，消耗资源更少。 相关信息CNN的核心是卷积层，但卷积的进行会消耗大量的计算资源，因此出现了许多量化压缩的方法。flattened convolution通过对长宽通道三个维度依次卷积来近似标准卷积，但忽略了各维度之间的关系，因此无法在各种计算机视觉任务中推广；深度可分离卷积将卷积分解成立深度和点卷积，提高了效率，被诸多典型的网络所应用。 此外，神经架构搜索也是近来新兴的寻找网络最优架构的方法。网络的量化、压缩与蒸馏也可以用来提高网络的效率，与文章所述方法存在正交性。 网络架构网络架构如图所示： 网络采用三条分支来分别对三个维度进行编码，深度采用卷积核为${k_D} \in \mathbb{R}^{1 \times n \times n}$，宽度采用卷积核为${k_W} \in {\mathbb{R}^{n \times n \times 1} }$，高度采用卷积核为${k_H} \in {\mathbb{R}^{n \times 1 \times n} }$，产生的特征图为： {Y_{Dim} } = \{ {Y_D},{Y_W},{Y_H}\} \in {\mathbb {R}^{3D \times H \times W} }之后对三个维度的信息进行融合，这里分为两个步骤，分别是局部融合与全局融合。这里的局部融合将特征图看作$D$个组的张量，每组有三个维度的信息，因此使用了${k_g} \in {\mathbb{R}^{3 \times 1 \times 1} }$的卷积核，产生特征图${Y_G} \in {\mathbb{R}^{D \times H \times W} }$。由于是卷积核对$D$组特征图分别进行处理，因此这里看作是局部融合操作。全局融合则是分别学习特征图空间与深度两个维度的语义表示，之后将其融合，具体来说就是在空间上使用了${k_S} \in {\mathbb{R}^{1 \times n \times n} }$大小的卷积核学习空间语义；深度上收到了SE unit的启发，使用了两个全连接层来学习深度的语义信息，为了学习到非线性的语义关系，中间还使用了ReLU激活函数，最后，使用深度语义信息来给空间语义信息加权，完成了全局信息的融合。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Programmer and Mathematics (一)]]></title>
    <url>%2F2021%2F01%2F09%2FProgrammer-and-Mathematics-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[多项式从加密开始，假设现在有一条秘密消息，将其分成10个部分进行编码，接收方只要知道任意6个部分，就可以重建消息，但如果少于6个部分，甚至不能确定原始消息的一小段，要实现这种方案，多项式足以。 定理2.1：实系数单变量多项式是输入为实数输出也为实数的一种函数，形式如下： f(x) = {a_0} + {a_1}x + {a_2}{x^2} + ... + {a_n}{x^n}其中${a_i}$是$f(x)$的系数，且必须是非负整数，多项式的次数为$n$。 从程序语言来讲，一个关于系数的数组就可以限定一个多项式，例如a[i]就代表${a_i}$，数组的长度就代表多项式的次数。 多项式是非常重要的，其内部的乘加特性，可以延申到所有的算数运算。现在暂时扩展到多变量，在程序语言中的与或非，就是非常简单的多变量多项式，但最终能产生全部的算法范围。 考虑一种特殊情况，虽然次数存在，但系数全部为0。在这种情况下，虽然是合理的但次数就失去了其应有的意义，因此，“按惯例”，最后一个系数${a_n}$应该是非零的，同时，特别定义$f(x) = 0$是零多项式，其次数为-1。 当定义一个函数的时候通常使用如下的表示：$f:A \to B$。所有可能的输入被称作域，所有可能的输出被称作范围。在数学中，范围是所有真实输出的集合，输出的类型称为共域。在上述的表达中，我们指定$A$代表域，$B$代表共域。 了解了一些基本的概念之后，可以着手实现前文所述的加密，这里需要利用到以下的定理：经过给定点集的多项式的存在性与唯一性定理。 定理2.2：对任意整数$n \ge 0$和属于$\mathbb{R}^{2}$的$n+1$个点的点集$({x_0},{y_0}),({x_1},{y_1}),…,({x_n},{y_n})$，其中${x_0} &lt; {x_1} &lt; {x_2} &lt; … &lt; {x_n}$，存在一个唯一的$n$次多项式，使得对所有的$i$有$p({x_i}) = {y_i}$。 其中，$\mathbb{R}^{2}$代表了一对实数，每个实数都属于$\mathbb{R}$，类似的，$\mathbb{Z}^{3}$代表一个整数的三元组。 这个定理可以用一种更简短的方式陈述：存在唯一的$n$次多项式，其经过了$n+1$个点的选择。当看见一个新定理的时候，要做的第一件事就是写下一个最简单的例子，这样除了能够简化定理，还能够提供示例，为审阅证明定理的时候使用。例如对以上的定理选择$(7,4)$这个例子，这是一个零次多项式，函数唯一且确定，为$f(x)=4$。接下来稍微复杂一点，考虑数据为$(2,3),(7,4)$，这是一个一次多项式，也能很容易的确定这个多项式应为$f(x) = \frac{ {13} } {5} + \frac{1} {5}x$。在几何上，次数为1的多项式是一条直线。这是显而易见的，在两点之间有唯一的一条直线。此外，定理还指出了${x_0} &lt; {x_1} &lt; {x_2} &lt; … &lt; {x_n}$，那么来考虑下${x_0} = {x_1}$的情况，例如$(2,3),(2,5)$。 我们不考虑真实答案，只猜测可能没有次数为1的多项式经过这两点，或者有多个次数为1的多项式经过这两点，那么就破坏了唯一性。因此，我们应该尝试以一种更加精确的方式阅读定义。 现在考虑证明2.2，将包括两个部分，存在性和唯一性。首先，我们将证明存在一个满足要求的多项式，然后证明如果两个多项式都满足要求，则它们必须相同。下面将通过直接构造的方式来证明存在性。与前文类似，我们还是从最简单的方式开始，但是是以一种通用的形式。此时如果是一个点$(x_1, y_1)$，则多项式为$f(x) = {y_1}$，两个点的情况我们直接写成以下的形式$f(x) = {y_1}\frac{ {x - {x_2} } } { { {x_1} - {x_2} } } + {y_2}\frac{ {x - {x_1} } } { { {x_2} - {x_1} } }$，显然，满足要求，且式中已经包含了${x_1} \ne {x_2}$。将其简化为多项式的标准形式： f(x) = \frac{ { {x_1} {y_2} - {x_2} {y_1} } } { { {x_1} - {x_2} } } + (\frac{ { {y_1} - {y_2} } } { { {x_1} - {x_2} } })x显然，$x$的幂没有出现大于1的情况，而且没有出现两个$x$相乘的情况，那么，可以确信此多项式的次数为1. 三个点的多项式，我们也可以按照以上的方式进行构造： f(x) = {y_1}\frac{ {(x - {x_2})(x - {x_3})} } { {({x_1} - {x_2})({x_1} - {x_3})} } + {y_2}\frac{ {(x - {x_1})(x - {x_3})} } { {({x_2} - {x_1})({x_2} - {x_3})} } + {y_3}\frac{ {(x - {x_1})(x - {x_2})} } { {({x_3} - {x_1})({x_3} - {x_2})} }同理，$n+1$个点的多项式就很容易构造了，如下： f(x) = \sum\limits_{i = 0}^n { {y_i}(\prod\limits_{j \ne i} {\frac{ {x - {x_j} } } { { {x_i} - {x_j} } } } )}此时，其实已然证明了存在性，因为每一项都是$n$次的，这显然是一个$n$次的多项式。 下面展示以下上式中某些数学符号的代码展示，有以下的例子： f(x) = \sum\limits_{i = 0}^n {bar(i)(\prod\limits_{j \ne i} {foo(i,j)} )}123456789101112int i, j;sometype theSum = defaultSumValue;for (i = 0; i &lt;= n; i++) &#123; othertype product = defaultProductValue; for (j = 0; j &lt;= n; j++) &#123; if (j != i) &#123; product *= foo(i, j); &#125; &#125; theSum += bar(i) * product;&#125;return theSum; 下面证明唯一性，依赖如下定理： 定理2.3：零多项式是实数内唯一一个次数最多为$n$，但有超过$n$个不同根的多项式。 现在来进行证明，假设有两个$n$次的多项式，经过点集$({x1},{x_2}),…,({x{n + 1} },{y_{n + 1} })$，这两个多项式可以相同也可以不同，我们所要做的是证明这两个多项式必须相同，那么就证明了唯一性。现在构造这样一个多项式$(f - g)(x)$，定义$(f - g)(x) = f(x) - g(x)$，如果$f$的系数为$a_i$，$g$的系数为$b_i$，那么$f-g$的系数为$c_i=a_i-b_i$，显然$f-g$是一个多项式。我们对这个多项式了解多少呢，首先，这个多项式的次数最多是$n$，而且我们知道$(f - g)({x_i}) = 0$。现在我们使用定义2.3，我们假定$f-g$的次数为$d \leqslant n$，我们知道此多项式的根不超过$n$个，除非它是零多项式，但有$n+1$个点（即上文所述点集中的点）可以使上式成立，因此这是一个零多项式，因此$f$跟$g$相同。 既然已经通过给定点集证明了$n$次多项式的存在性和唯一性，那么就可以为其命名，成为给定点的插值多项式，插值意味着获取点集，并找到通过这些点的唯一最小次多项式。 代码实现以下将编写一个插值点的python程序，将假设存在一个多项式类，该类接受一系列参数并生成多项式，如下： 1234567891011def interpolate(points): &quot;&quot;&quot;Return the unique polynomial of degree at most n passing through the given n+1 points.&quot;&quot;&quot; if len(points) == 0: raise ValueError(&apos;Must provide at least one point.&apos;) x_values = [p[0] for p in points] if len(set(x_values)) &lt; len(x_values): raise ValueError(&apos;Not all x values are distinct.&apos;) terms = [single_term(points, i) for i in range(0, len(points))] return sum(terms, ZERO) 输入点集后，通过single_term函数生成单项，将这些单项相加即是多项式，生成单项的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243def single_term(points, i): &quot;&quot;&quot;Return one term of an interpolated polynomial. This method computes one term of the sum from the proof of Theorem 2.2. In particular, it computes: y_i \product_&#123;j=0&#125;^n (x - x_i) / (x_i - x_j) The encapsulating `interpolate` function sums these terms to construct the final interpolated polynomial. Arguments: - points: a list of (float, float) - i: an integer indexing a specific point Returns: A Polynomial instance containing the desired product. &quot;&quot;&quot; the_term = Polynomial([1.]) xi, yi = points[i] for j, p in enumerate(points): if j == i: continue xj = p[0] &quot;&quot;&quot; The inlined Polynomial instance below is how we represent (x - x_i) / (x_i - x_j) using our Polynomial data type (where t is the variable, and x_i, x_j are two x-values of data points): (x - x_i) / (x_i - x_j) = (-x_j / (x_i - x_j)) * t^0 + (1 / (x_i - x_j)) * t^1 &quot;&quot;&quot; the_term = the_term * Polynomial([-xj / (xi - xj), 1.0 / (xi - xj)]) # Polynomial([yi]) is a constant polynomial, i.e., we&apos;re scaling the_term # by a constant. return the_term * Polynomial([yi]) 这里利用了上文所述的构造方法，每一项为${y_i}(x - {x_j})/({x_i} - {x_j})$，这里将其分解成了${a_0} = - {x_j}/({x_i} - {x_j})$和${a_1} = 1/({x_i} - {x_j})$来生成一个简单的多项式。 实践以下将使用多项式插值来实现加密。假设武林盟主有五个得力手下，他向他们分享一个秘密，秘密以二进制表示，也许这个秘密是一张藏宝图。问题在于这些手下是贪婪的，如果直接把秘密给他们，或许有人会直接独吞藏宝图；如果只给一部分，他们也有可能直接找到藏宝图，更糟糕的是，如果三个人聚在一起，很可能会猜中剩余的部分，排除掉另外两人。因此，为了安全，这个秘密应该具有以下的属性： 每个人只有获得了部分秘密，且这部分是独一无二的； 如果任意四个人聚在一起共享秘密，他们也不能得到完整的秘密； 如果五个人全部聚在一起，他们才能得到完整的秘密，拿到藏宝图。 实际上，任意四个人聚在一起不只是不能获取完整的秘密，他们甚至破译不出任何秘密。神奇的是是有这种方案的，无论有多少个人（$n$），或者是希望有多少组（$k$）能重建秘密，这都是可能的。以下给出这种方案，即使用多项式插值。我们将秘密用整数$s$表示，现在我们想让五个手下齐聚能得到秘密，因此$k$就是5，那么我们要构造的多项式的次数就是$k-1$也就是4，系数随机生成即可，然后将$f(1),f(2),f(3),f(4),f(5)$分发作为秘密的部分分发给手下，这样，只有五个人齐聚才能拿到藏宝图。]]></content>
      <categories>
        <category>文章</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割部分文章概览（四）]]></title>
    <url>%2F2019%2F05%2F23%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E9%83%A8%E5%88%86%E6%96%87%E7%AB%A0%E6%A6%82%E8%A7%88%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[此部分是关于部分语义分割论文的大致浏览 十一、FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation目的：在网络的设计中，空洞卷积虽然能够增大网络的感受野，但一般在使用空洞卷积的时候不进行下采样操作，这就导致了计算资源跟内存的占用。本文作者力求在使用下采样的情况下，通过设计一个联合上采样金字塔模块，逼近使用空洞卷积的效果，这样效果没有变差，而且计算量跟存储占用大大减小。 设计思想：经过分析，作者发现空洞卷积操作相当于将先将输入特征图进行拆分，再进行卷积操作，之后合并即可，而跨步卷积则是相当于先进行卷积操作，之后进行reduce操作。如上图所示，这里利用的是一种联合上采样的思想，不管是空洞卷积还是跨步卷积，其输入的特征图是一致的。对跨步卷积来说，当进行了reduce操作之后，相当于执行了一个下采样操作，之后经过不断的卷积得到最终的结果。而空洞卷积则是不进行下采样，直接进行卷积操作，相当于直接对高分辨率的输入特征图进行处理。我们知道，对于联合上采样来说，可以通过低分辨的输入输出得到一个映射，而这个映射能近似的将高分辨率的输入映射到高分辨率的输出。本文正是利用了这样一种思想来模拟一些分割网络中的空洞卷积的设计。 网络设计：首先将特征图转换到同一个嵌入空间，方便进行融合处理，之后通过扩张率不同的空洞卷积学习低分辨的输入与低分辨率输出的映射，即学习$y_m^0$与$y_s$之间的映射关系，而并行的普通卷积则学习$y_m^0$与$y_m$之间的关系，这样一个过程模拟一个映射，这个映射由低分辨率得到，用来处理高分辨率的输入，为了完成对空洞卷积的模拟，还需要对得到的特征图进行合并，这里进行了通道的连接，最后利用一个卷积将学到的特征转换成最终的输出。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割入门的简单指南]]></title>
    <url>%2F2019%2F04%2F15%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E5%85%A5%E9%97%A8%E7%9A%84%E7%AE%80%E5%8D%95%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[语义分割是一种在图像上将标签分给每一个像素的过程。这与分类形成了鲜明的对比，分类任务是将单个的标签分配给整张图片。语义分割将同一类的不同目标视为相同的对象。而实例分割则是将同一类的不同目标视为不同的对象（或者叫做实例）。通常情况下，实例分割比语义分割更加困难。本博客探讨了基于传统的与深度学习理论来进行语义分割的一些方法。而且，还讨论了一些较为流行的损失函数选择与应用。 传统方法在深度学习时代到来之前，我们使用了大量的图像处理技术将图像分割成许多感兴趣的的区域。我们将一些流行的方法罗列在下方： 灰度分割最简单的语义分割方法是找到某个满足硬编码的规则或属性的区域，再为这个区域分配特定的标签。这种规则可以根据像素的属性来构建，例如它的灰度级。使用这种技术的一种方法是Split and Merge算法。这种算法递归的将图像分割成子区域，直到分配了特定的标签，之后合并带有相同标签的相邻区域。 这种算法的问题在于其规则必须是一种硬编码。而且，仅仅使用灰度信息来表示诸如人类这样的复杂类别是极其困难的。因此，我们需要使用特征提取与优化技术来学习这样复杂类别的正确表示。 条件随机场我们考虑通过训练一个模型给每个像素分类来分割图像。如果模型不够完美，我们可能会获得一个不那么自然的嘈杂分割结果（例如下图所示，狗跟猫的像素混在一起）。这种事情可以通过考虑像素之间的先验关系来避免，比如目标的像素是连续的，因此相邻的像素趋向于有着相同的标签。为了建模这种关系，我们考虑使用条件随机场（CRFs）。 CRFs是一类针对于结构化预测的概率建模方法。与离散的分类器不同，CRFs在做出预测之前，会考虑近邻语义，例如像素之间的关系。这就使这种方法成了语义分割的理想选择。本小节探讨了CRFs在语义分割中的使用。 图像中的每一个像素都与一组可能状态的有限集有关。在我们的例子中，标签是可能状态的集合。将一种状态分配给一个像素所花费的代价称为unary cost。为了建模像素间的关系，我们将一对标签$(u,v)$分配给一对像素$(x,y)$的代价称为pairwise cost。我们可以从成对的像素来考虑，把它们看作直接的近邻（Grid CRF），或者我们可以从图像的所有像素来考虑（Dense CRF）。所有像素的unary cost和pairwise cost之和作为CRF的energy(或者叫做代价或损失)。通过最小化上述值来获得较好的分割结果。 深度学习方法深度学习极大的简化了语义分割的方法，并产生了极高质量的结果。在本章节中，我们讨论了训练这些深度学习方法的流行的模型架构与损失函数。 1. 模型结构用于语义分割最流行最简单的架构是全卷积网络(FCN)。在论文FCN for Semantic Segmentation中，作者使用了FCN通过卷积操作下采样了图像到一个较小的尺寸（同时得到了更多的通道），这些卷积的集合一般被称为编码器。之后，编码的结果要么经过双线性插值，要么经过一系列的转置卷积，来进行上采样操作。这些转置卷积的集合一般被称作解码器。尽管这种基础的架构非常有效，但也有一些缺点。一种缺点就是由于这些转置卷积（或者叫做反卷积）操作会输出不均匀的重叠，会存在棋盘伪像的现象。另一个缺点是在编码的过程中损失了信息，从而在边缘处分辨率较差。 之后有学者提出了一些改善基本FCN模型性能的方法，以下是一些被证明有效的较为流行的解决方案。 U-NetU-Net是简单的FCN架构的升级版本。在卷积块的输出和与之相匹配的转置卷积的输入之间，Unet网络加入了跳跃连接。这种跳跃连接使梯度能够更好的流动，并提供了来自不同尺度图片的信息。较大尺度图片的信息（来自浅层）可以帮助模型分类更加精准，小尺度的信息（来自深层）可以帮助模型分割或者定位的更好。 Tiramisu ModelTiramisu模型与Unet较为相似，不同之处在于这种模型使用了DenseNet中的Dense blocks来做卷积与转置卷积。一个Dense block有一些卷积层组成，前面所有层的特征图都作为后面层的输入。这种合成的网络具有极高的参数效率，可以更好的利用前面一些层的特征。这种方法也存在缺点。由于ML框架之间的连接操作，这种方法的内存效率不是很高（需要较大的GPU才能运行）。 多尺度方法一些深度学习模型明确的使用了一些方法来整合多尺度的信息。举例来说，PSPNet使用四种不同的卷积核大小和步长来对卷积网络的输出做池化操作，之后使用双线性插值将所有池化的输出与卷积层的输出特征图进行上采样，在通道维度上连接它们。最后对这个连接的输出进行卷积产生最终的预测结果。空洞卷积是一种结合多尺度信息的有效方法，而且其没有增加参数的数量。通过调整空洞率，相同滤波器的权重在空间上可以分布的更广，这使得网络可以学习到更加全局化的上下文语义信息。DeepLabv3使用了不同空洞率的空洞卷积来捕获不同尺度的信息，而且没有明显的损失图像的分辨率。他们实验了一种级联的空洞卷积，也实验了一种并联的方式，被称为空洞空间金字塔池化（如下图所示）。 混合CNN-CRF方法一些方法使用了CNN作为特征提取器，然而将输出的特征作为unary cost(potential)输入到了密集的CRF中。由于这种混合的CNN-CRF方法具有较强的像素关系建模能力，因此能得到较好的结果。而某些方法直接将CRF嵌入到了神经网络中，如同在CRF-as-RNN中密集CRF可以被RNN建模。如上图所示，这使得端到端训练成为可能。 2.损失函数与普通的分类不同，语义分割必须挑选一些不同的损失函数。下面是一些语义分割较为常用的损失函数： Pixel-wise Softmax with Cross Entropy语义分割标签的尺寸必须与原始图片相同。标签可以被编码成one-hot形式，如下图所示：由于标签是一种比较方便的one-hot形式，它可以直接被用来和ground truth（目标）一起计算交叉熵。然而，在求交叉熵之前，必须对预测得到的各个像素值执行softmax操作，这是因为每一个像素值都可以代表一类目标。 Focal LossRetinaNet提出的Focal Loss是标准交叉熵的升级版，可以用于一些极端的类不平衡的例子中。 考虑如下图所示的标准交叉熵（蓝色），即使我们的模型对某个像素值的类别非常自信（达到80%），它仍然具有较大的损失值（大约0.3）。另一方面，当模型对某一类置信度非常高时，Focal Loss（紫色，gamma值为2）不会对模型进行惩罚（当置信度为80%时，损失几乎为0）。 让我们用一个直观的例子来探索为什么Focal Loss效果如此显著。假设我们有一张总共10000个像素点的图片，图片只有两类：背景（0）和目标（1）。我们假设图片的97%是背景，目标只有3%。现在，假定我们的模型确定了80%的背景，但只确定了30%的目标。 当我们使用交叉熵的时候，背景像素的损失为$97\% \times 10000 \times 0.3 = 2850$，目标像素的损失值为$3\% \times 10000 \times 1.2 = 360$。显然，置信度高的类（即背景类）的损失占主导地位，模型缺乏学习目标类的动力。作为对比，当使用focal loss时，背景类产生的损失值为$97\% \times 10000 \times 0 = 0$，这使得模型能更好的学习目标类。 Dice LossDice Loss是另一种处理语义分割类不平衡的较为流行的损失函数。这种损失函数由V-Net提出，可以用来计算预测与ground truth之间重叠的部分。Dice系数表示如下：我们的目的是使预测与真值的重叠部分最大化。因此，我们通常最小化$(1-D)$来达到相同的目的，因为大多数的机器学习库只提供最小化的选项。尽管Dice Loss对于类不平衡的样本效果较好，但我们可以看到其梯度计算公式的分母存在平方项。当某些值很小时，我们可能获得较大的梯度，从而导致训练不稳定。 应用语义分割有各种各样的实际生活应用，下面是一些比较常见的用例。 自动驾驶通常使用语义分割来识别车道、车辆、行人和其他感兴趣的目标。分割的结果用来对如何驾驶车辆做出正确的决策。 自动驾驶的一个限制是要求操作必须是实时的。上述问题的解决方案是将GPU与车辆本地集成到一起。为了增强上述方案的可操作性，可以使用更加轻量化的网络（较少的参数），或者可以使用在一种极限拟合神经网络的技术。 医疗图像分割人们通常使用语义分割来识别医学扫描图中的显著性元素。主要用于识别类似于肿瘤的异常。算法的准确率和低召回率对于这种应用来说非常关键。我们还可以自动执行一些不太重要的操作，例如从3D语义分割扫描图像中估计器官的体积。 景物理解语义分割通常是复杂任务的基础，例如场景理解和视觉问答。场景图或者标题通常是场景理解算法的输出。 Fashion Industry服装行业通常使用语义分割从图像中提取衣服的像素块，用来给零售店提供一些相似的建议。更高级的算法可以给图像中的人物进行重新装扮。 卫星图像处理卫星图像使用语义分割来识别陆地类型。比较典型的例子包括分割水体来提供准确的地图信息。其他高级的用例包括绘制道路，识别作物类型，识别免费停车位等等。 结论深度学习极大的增强和简化了语义分割算法，为算法的实际应用铺平了道路。本博客列出的概念并非详尽无遗，因为研究团队正努力提高这些算法的准确性与实时性。无论未来发展如何，这篇博客介绍了当下这些算法一些流行的变式以及实际的应用。 本文译自A Simple Guide to Semantic Segmentation]]></content>
      <categories>
        <category>文章</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文阅读-Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation]]></title>
    <url>%2F2019%2F03%2F24%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Auto-DeepLab-Hierarchical-Neural-Architecture-Search-for-Semantic-Image-Segmentation%2F</url>
    <content type="text"><![CDATA[研究目标神经架构搜索的网络已经在图像任务中取得了比人类设计的网络更好的成绩，由此，作者提出将神经架构搜索应用到语义分割领域，来获取较优的分割结果。 亮点：1、 提出了网络级架构搜索空间来联合单元级架构搜索空间进行搜索，寻找更优的结构。 2、开发出了一个可微的连续公式，可以在两级分层架构上进行有效的搜索。 相关信息：1、神经架构搜索旨在自动设计网络结构，从而减少人工的时间与工作量。早期的工作大都试图直接建立整个网络，后来转向搜索可重复单元（例如resnet块），外部网络级结构则通过人类设计，即控制分层计算的内部单元级使用自动搜索，而控制分辨率的网络级则使用手动设计。 2、神经架构搜索在图像分类任务上取得了较大的成功，但直接应用在语义分割任务上则效果不佳，原因是NAS一般使用从低分辨率到高分辨率的迁移学习，而语义分割是密集型的预测任务，需要直接在高分辨率图像上进行学习，这就需要设计一个更加松弛的搜索空间来捕捉高分辨率的变化，同时需要更加高效的搜索技术，因为需要更多的计算。 网络设计1、单元级搜索空间：将一个小的全卷积模块定义为一个单元，一个单元是由B个块组成的有向无环图。每个块是双分支结构，单元$l$中的块$i$通常用一个5元组表示$({I_1},{I_2},{O_1},{O_2},C)$,其中$I_1$与$I_2$是输入张量的选择，$O_1$与$O_2$是输出张量的选择，$C$是组合两个分支的方法。单元的输出张量$H^l$是所有块输出张量${ H_1^l, \ldots ,H_B^l} $的组合。可能的输入张量是由前两个单元的输出以及当前单元当前块之前的输出组成。可能的层类型O为： 1）$3 \times 3$深度分离卷积 2）$5 \times 5$深度分离卷积 3）$3 \times 3$空洞卷积，空洞率为2 4）$5 \times 5$空洞卷积，空洞率为2 5）$3 \times 3$的平均池化 6）$3 \times 3$的最大池化 7）跳跃连接 8）无连接对于可能的组合操作$C$的集合，采用简单的对应元素相加的方法。由于以上给出的都是离散的方式，搜索空间较大，为了方便用梯度下降法求解，需要转换成连续空间的搜索。这里所作的操作是对两个分支分别加权: H_i^l = {\alpha ^1}*{O_1}({I_1}) + {\alpha ^2}*{O_2}({I_2})其中，${\alpha ^1} + {\alpha ^2} = 1$ 2、网络级搜素空间：所谓的网络级搜索空间，其实就是特征图分辨率改变步骤的选择，在由于密集图像预测的各种网络中，一般有如下的原则：1）下一层的空间分辨率要么是两倍大，要么是两倍小，要么保持不变2）最小的空间分辨率是原图像分辨率的下采样32倍3）开始第一层的特征图一般是原来的四倍小网络级搜索空间示例如下：为了建立连续松弛，每层$l$至多有四个隐藏状态$\ {}^4{H^l},{}^8{H^l},{}^{16}{H^l},{}^{32}{H^l}\ $，左上标表示空间分辨率，分辨率可能从三个地方进行转移，分别是分辨率是其一半的地方，分辨率相同的地方以及分辨率是其两倍的地方，分别给于三个$\beta $权重，且其和为1，所以我们可以将其视为转移概率，而要找到一条最大概率的路径可以通过维特比算法达成。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文阅读-Deformable Convolutional Networks]]></title>
    <url>%2F2019%2F03%2F15%2F%C2%96%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%C2%96Deformable-Convolutional-Networks%2F</url>
    <content type="text"><![CDATA[目的：卷积核固定的尺寸在一定程度上限制了模型对于图像几何建模的能力，论文提出了可变形卷积来致力于解决这个问题。 相关信息：对于增强模型的几何建模能力，目前有两种比较普遍的方法：一是对数据进行相应的增强，即对图像进行各种几何变换来丰富数据集，再利用网络学习相应的几何建模能力；二是利用transformation-invariant特征与算法。但这两种方法都有相应的缺点，第一，我们内在假设了变换的先验已知，如果遇到了没有见过的几何变换，就无法进行几何建模，第二，手动设计的特征与算法无法处理过于复杂的变换。 网络设计：1、作者设计了一个可变形卷积模块，实质是卷积核不变，但采样点的位置发生偏移，变成了一种不规则的采样，以此来学习图像的几何变换，示意如下：卷积总共分两路，下面一路是标准的卷积，上面一路生成一定的偏移，之后与下路相加进行线性插值，确定采样点的坐标，再进行卷积。2、作者还设计了一种可变形RoI池化来代替普通的RoI池化，与1相似，也是偏移了采样点，示意如下：3、PS RoI池化设计如下：]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割部分文章概览（三）]]></title>
    <url>%2F2019%2F02%2F24%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E9%83%A8%E5%88%86%E6%96%87%E7%AB%A0%E6%A6%82%E8%A7%88%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[此部分是关于部分语义分割论文的大致浏览 八、Attention U-Net: Learning Where to Look for the Pancreas目的：简化用于医学成像的分割模型，加入注意力机制后可以取消额外的定位模块，且不耗费太大的运算量。 网络设计：为了突出用于分割的显著特征并且抑制不相关的特征，网络集成了注意力门控机制，且利用了unet网络，通过渐进的下采样获得不同尺度的特征，利用跳跃连接，使用了门控连接了粗细两个尺度的信息来提取更加丰富的语义信息用于分割，网络示意图如下： 九、LadderNet: Multi-path networks based on U-Net for medical image segmentation目的：改进U-Net网络，提高网络分割的精确度 网络设计：1、作者认为U-Net网络分割精度受限的原因是网络信息流动的路径有限，所以，为了提高网络的精度，作者增加了信息流动路径，提出了一种阶梯U-net网络，即多个U-Net网络的结合，网络结构如下：作者认为，这样的U-Net结构可以认为是许多个FCN网络的集合，当然能够提取更加丰富的特征，进而提高分割精度。2、此外，作者使用了共享参数的技巧，网络中的标准残差块参数共享，大大减少了网络本应有的参数与训练难度 十、CCNet: Criss-Cross Attention for Semantic Segmentation目的：使用长距离注意力依赖生成注意力图，利用注意力图辅助分割 网络设计：1、如果利用每个像素点与全局的关系来生成注意力，耗费的计算资源太大，所以作者在这里只利用了像素点所在位置的那一行与那一列，如下图所示：2、如果只利用交叉行的信息会使得语义信息太过稀疏，所以论文采用了一种循环的方式（这里暂时没看懂，后期补充）。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文阅读-Bag of Tricks for Image Classification with Convolutional Neural Networks]]></title>
    <url>%2F2018%2F12%2F31%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Bag-of-Tricks-for-Image-Classification-with-Convolutional-Neural-Networks%2F</url>
    <content type="text"><![CDATA[主题目前许多计算机视觉任务精度的提高得益于对训练过程的一些细微调整，这其中存在了许多小技巧，本文着重介绍了这些小技巧。 训练过程中的基本原则1、 图像的预处理： 1） 对图像随机取样并将数据转换为32位浮点型，像素值取值范围为0到255 2） 随机裁剪长宽比在[3/4, 4/3]区域的矩形，随机取样的范围为[8%, 100%]，之后将图像放缩至224*224的大小 3） 以0.5的概率水平翻转 4） 缩放色调、饱和度、亮度，缩放系数在[0.6,1.4]中均匀采样 5） 从正态分布中(0,0.01)中采样一个系数并加入pca噪声 6）通过对RGB通道减去123.68、116.779、103.939，除以58.393/57.12,57.375来规范化图像数据 2、 对于验证集的处理，将图片短边缩放至256像素并保持其纵横比，之后以图像中心为中心裁剪至224*224并规范化，不使用其他变换。3、 卷积层与全连接层权重初始化使用xavier算法，即权重在[-a,a]中随机取值，$a = \sqrt {6/({d_in} + {d_out})} $，这里d代表输入输出通道；所有的偏置项初始化为0，对于batch Normalization层，$\gamma$初始化为1，$\beta$初始化为0.4、 训练中梯度下降方法使用NAG，训练模型以8块GPU训练120个epoch，batchsize为256，学习率初始为0.1，之后在第30个、60个、90个epoch时分别缩小10倍。 学习率调整策略一般来说，我们倾向于使用较大的批量大小，这样可以提高训练效率，但大的批量大小却会导致收敛速度的减慢，为了解决这个矛盾，有以下几种方法： 1） 学习率线性扩大 大的批量意味着收敛速度的减慢，所以要增大学习率。在何恺明的实验中，批量大小为256的学习率为0.1，之后增大批量大小为b，则学习率变为0.1*b/256。 2） 学习率预热 开始训练时权重是随机的，这时如果使用较大的学习率会使得数值不稳定，所以采用的策略是开始学习率较低，训练几个batch后恢复初始学习率，即设置初始学习率为$\eta$，当第i个batch时，学习率为$i\eta /m$，其中$1 \le i \le m$。 3）zero $\gamma $ 采用策略是开始训练时训练更少的层，即将残差块最后一个bn置于0。 4）无偏衰减 采用策略是只将L2正则化应用到权重上来避免过拟合，其他参数不经过正则化。 低精度训练利用16位进行训练可以有效减少模型的训练时间 模型优化如图所示：第一种修改是将33卷积核的步长修改为2,11卷积核的步长修改为1，这样可以避免输入内容的丢失。第二种修改是将77卷积用3个33的卷积替换。第三种修改是在1*1卷积前增加平均池化。 训练过程的微调1、 余弦学习率下降，采用的公式为： {\eta_t} = \frac{1}{2}(1 + \cos (\frac{t\pi }{T}))\eta学习率示意图如下： 2、 标签平滑 修改真实的概率，以减少分类层的过拟合可能性，是为了防止网络太过自信于自己的判断。注意，应用标签平滑应当是过拟合较为严重的时候，其他情况则不适用。 3、 知识蒸馏 使用一个效果较好的大的预训练模型来辅助训练一个小模型，损失函数为： \ell (p,soft\max (z)) + {T^2}\ell (soft\max (r/T),soft\max (z/T))注意，teacher模型跟student模型最好是同一种网络结构。 4、混合训练 即随机把两个样本加权线性插值，作为新样本用于训练： \begin{array}{l} \hat x = \lambda {x_i} + (1 - \lambda ){x_j},\\ \hat y = \lambda {y_i} + (1 - \lambda ){y_j} \end{array}]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文阅读-Group Normalization]]></title>
    <url>%2F2018%2F12%2F29%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Group-Normalization%2F</url>
    <content type="text"><![CDATA[问题的提出Batch Normalization虽然是一种较好的防止过拟合的方法，但也有其缺陷：那就是随着批次的减小，BN的错误率会增加，但在一些cv任务中，又要求较小的批次，因此需要解决这个问题，伦文提出了一种Group Normalization的方法。 相关工作 Batch Normalization问题的产生：归根结底是不同阶段数据分布的不一致造成的，通常来说，训练阶段跟测试阶段的batch size是不同的，而现在大多数网络在测试阶段都是直接调用了训练阶段产生的均值与方差，这显然就是不合理的，因为数据分布出现了变化。 LN与IN避开了batch维度方面，有一定的效果，但仍然比不上本文的GN。 BR一定程度上减弱了批次小错误率高的问题，但仍没有从根本上解决。 Group Normalization的设计 论文表明，神经网络中的特征图进行语义表示其实也是成组的，那么，就可以对这些成组的特征图一起规范化。 一般来说，规范化用公式表达如下：{\hat x_i} = \frac{1}{\sigma_i}({x_i} - {\mu_i})主要是计算均值与方差，规范化之后，为了补偿表示能力可能有的损失，进行了一个线性变换：{y_i} = \gamma {({\hat x}_i)} + \beta不同的方法进行规范化的方式如图所示： 总结通过实验的对比，GN有着不错的效果，但由于目前BN是训练网络的一种十分有效的方法，许多超参数与结构对BN来说可能是最好的，但对于GN来说却可能不是最合适的，需要重新设计结构。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割部分文章概览（二）]]></title>
    <url>%2F2018%2F12%2F22%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E9%83%A8%E5%88%86%E6%96%87%E7%AB%A0%E6%A6%82%E8%A7%88%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[此部分是关于部分语义分割论文的大致浏览 五、Dual Attention Network for Scene Segmentation目的：场景分割是一项挑战性的任务，因为其蕴含的语义信息十分丰富，很难提取出这些丰富的语义来实现完美的分割。文中提出了一种双重注意力网络来试图解决这个问题。 相关信息： 提取丰富语义信息的一种方式是进行多尺度上的融合，这包括空洞金字塔池化，使用大的卷积核，或者利用编码译码结构来融合浅层与深层的语义信息。 另一种方式是通过RNN，来获取长距离的依赖，从而获得更丰富的语义信息，但这种方式太过依赖于网络长期记忆的学习结果。 注意力机制可以对长期依赖进行建模，后来出来的自注意力机制可以不引入外部信息，从自身出发，通过全局来增强内部的依赖性。 网络设计： 网络结构如下：网络使用了基于空洞卷积的FCN,首先使用Resnet网络下采样八分之一大小，之后通过并联的两个注意力模块增强语义信息，之后通过卷积操作输出结果。 空间注意力模块：首先将特征图复制三次，将其拉长为向量，通过B、C的相乘得到行列都为(H*W)的Gram矩阵，通过第三个复制向量D得到注意力图，之后进行加权增强语义的依赖。如下：{E_j} = \alpha \sum\limits_{i = 1}^N (s_{ji}{D_i}) + {A_j} 通道注意力模块：基本思想与空间注意力模块大致相同，不做描述。 六、Pyramid Attention Network for Semantic Segmentation目的：本文的目的是为了更好的利用全局信息，从而对不同尺度的目标进行分割，作者设计了一种金字塔注意力网络来获取更加丰富的语义信息，最终得到更加精细的分割结果。 相关信息：目前的分割网络普遍存在两个问题： 小尺度目标不容易检测，经常出现轮廓分割的较好，但分类出现错误的问题，deeplab对此的解决方案是使用空洞卷积，但会产生grid artifacts，而PSPNet则是使用了全局平均池化，但这样一来位置信息会丢失。 高级语义信息对低级语义信息没有帮助，一般来说高级语义信息有利于分类，而低级语义信息则保留了较多的位置信息。 网络设计 网络为了规避deeplab的缺陷，放弃了空洞卷积，同时为了译码时生成较好的结果，利用高层语义信息来指导低层语义分辨率的恢复。网络总体设计如下： 网络放弃了空洞卷积，但为了获取更加丰富的语义信息，这里利用了一种金字塔结构来进行多尺度信息的获取，同时增加了全局平均池化作为辅助。 目前已知缓慢增加图片的分辨率恢复的效果较好，同时，文中设计了一种注意力机制，通过高级语义信息生成关于通道的注意力，依次来指导图片的恢复。 七、Adaptive Affinity Fields for Semantic Segmentation目的：语义分割能够实现像素级的分割，但对于一些语义信息不明显的区域区分不够好，如前景与背景太过相似，就难以实现较好的分割效果。论文为了解决这个问题，引入了对结构的推理，提出了自适应相似场。在实质上，其实是对损失函数的修改，将整个问题看作一个最优化问题。 相关信息： 目前也有一些利用结构推理来帮助分割的方法，例如CRF，可以从视觉上来匹配目标的相似度，可以被用作分割网络的后处理阶段，用来改善分割效果，但花费的推理时间较长，同时对变化比较敏感；GAN也可以用来改善分割效果，但不易训练，同时容易出现模式崩溃。 解决方案 目前大多数的分割网络的损失函数都是以像素点为对象的交叉熵损失函数，这样就只关注了像素，而缺失了对像素之间关系的考量，例如一辆车行驶在路上，我们很容易从两者的关系而确定目标是车辆。因此，文章在损失函数中引入了像素点的邻域。具体公式见论文。 具体来说，其使用的相似域损失函数是一种基于KL散度的相似域损失函数，详情参见论文。这种损失函数并非定义在图像上，而是定义在groundtruth上，通过groundtruth的引导，强迫同一类的聚合在一起，不同类的分离，而不管图像是什么样的。值得一提的是这个过程只发生在训练阶段，因此不耗费推理的时间。 对于CNN来说，一般都要求同样大小的卷积核，这其实是不合理的，论文提出了一种自适应的相似域损失函数，给与了不同类别不同的权重。具体公式见论文。 这样直接进行优化，会导致得到的最优解是一个非常小的值，不能达到自适应的目的，因此文中考虑了一种极端的方式，即在最坏的情况下找到最好的值，将其表述为一个极小极大问题，具体公式见论文。PS:这篇论文的公式太难打了，博客都显示不了，最后只能全部删除。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[语义分割部分文章概览（一）]]></title>
    <url>%2F2018%2F12%2F19%2F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E9%83%A8%E5%88%86%E6%96%87%E7%AB%A0%E6%A6%82%E8%A7%88%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[此部分是关于部分语义分割论文的大致浏览 一、The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation论文主要是利用了DenseNet杰出的性能，将其应用到了语义分割的任务之中，并对网络的结构做了细微的调整，使其更容易训练，最终达到了较好的分割结果。如图所示：为了更好的进行上采样，仅在Densenet层之后进行跨层连接，减小训练的难度。 二、DenseASPP for Semantic Segmentation in Street Scenes论文认为，对于较大分辨率的图片，获取更大的感受野与提取多尺度信息是两个比较重要的问题。为了同时解决这两个问题，论文在ASPP（空洞金字塔池化）上做了改动，使用了一种密集连接的方式（个人认为参考了Densenet网络），实现了较好的分割效果。通过这样一种串行的方式，的确取得了远大于ASPP的感受野，同时实现了多尺度的提取。 三、BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation论文研究了如何在不牺牲精度跟分辨率的前提下保证较高的实时分割效率。网络结构如下所示：为了保证在语义分割中比较重要的空间分辨率与感受野，论文设计了两条路径，一条是空间路径，由三层卷积组成，目的是取得分辨率较高的1/8特征图；一条是语义路径，使用了一种轻量化模型Xception来快速增加感受野，同时做了一个最大池化操作使得感受野最大化。为了融合两部分的特征图，论文提出了一个特征融合模块与注意力优化模块。同时，为了辅助训练，在主损失函数之外还增加了两个辅助损失函数进行辅助训练。 四、ICNet for Real-Time Semantic Segmentation on High-Resolution Images问题的引入与介绍论文使用了多分辨率分支与标签引导来处理实时语义分割的问题，利用了PSPnet网络的基础框架，虽然略微牺牲了网络的分割精度，但大大缩短了网络推理的速度。论文主要有三个贡献： 提出了一种创新的图像级联网络，利用了低分辨率的语义信息与高分辨率的细节信息来进行语义分割。 提出的级联特征融合单元与级联标签导向来细化分割结果。 ICNet实现了5倍的加速，降低了5倍的内存。 网络设计 通过分析，计算复杂度与空间分辨率有较大关系，随着空间分辨率的提高，计算复杂度成平方的形式增加 直觉上来说，下采样输入、缩小特征图与模型压缩可以提升分割速度，实际上也确实如此，但这样会导致分割结果惨不忍睹。 所以作者设计了一种图像级联网络，语义分割的推理阶段最为耗费时间，所以这里使用了低分辨率的图片，使用的网络是经典分割网络；为了细化分割结果，又使用了较高分辨率的图片来补充信息，这里使用的是较为轻量化的网络。网络结构如下所示： 特征融合单元：融合单元如下图所示这里F1经过上采样之后还进行了空洞卷积，是为了融合近邻的语义。 级联标签引导：对groundtruth进行不同的下采样，以引导不同分支的训练，这样损失函数就有三项。在测试阶段，抛弃低分辨率与中分辨率的两支，只使用高分辨率的支路。 模型压缩：论文采用的压缩策略是一种渐进式的压缩，即先压缩部分，进行微调，再进行压缩，最终实现完全的压缩。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文阅读-ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design]]></title>
    <url>%2F2018%2F12%2F08%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ShuffleNet-V2-Practical-Guidelines-for-Efficient-CNN-Architecture-Design%2F</url>
    <content type="text"><![CDATA[研究问题：进一步对模型进行精简，使其在移动端也具有良好的运行速度 亮点从目的出发找到设计原则，在设计原则的指导下来设计网络 相关信息 网络想要在移动端运行，则需要较低的运算复杂性，其衡量标准为浮点运算操作的数量，即FLOPs，目前大多数的网络都是通过组卷积与深度可分离卷积来降低FLOPs。 经过实验发现，降低了FLOPs，并不意味着网络的速度增加，FLOPs只是衡量速度的间接标准，我们需要找到衡量速度的直接标准。论文中经过实验发现，速度与内存访问成本（MAC）与网络的并行化程度有关。 实验与结论 卷积层的输入输出通道相等时，MAC最小。使用h与w代表输出特征图的尺寸，$c_1$ 与$c_2$代表输入与输出的通道数，则卷积层的FLOPs计算如下：$B = hw{c_1}{c_2}$，而对于MAC，对于1*1卷积，由于输入与输出特征图尺寸相同，所以有：${\rm MAC = }hw({c_1} + {c_2}) + {c_1}{c_2}$，由均值不等式，这里可以得到$hw({c_1} + {c_2}) + {c_1}{c_2} \ge 2hw\sqrt {c_1c_2} + {c_1}{c_2}$，将B代入可得：${\rm MAC}\ge{\rm2}\sqrt{hwB} + B/hw$，显然，等通道数相等时才能取得最小值。 过多的组卷积操作会增加MAC，使得速度变慢。对于1*1卷积来说，g代表组数，当使用了组卷积之后，B变为$B = hw{c_1}{c_2}/g$，MAC变为${\rm MAC=}hw({c_1} + {c_2}) + {c_1}{c_2}/g$，此时有：\begin{array}{c} MAC = hw({c_1} + {c_2}) + {c_1}{c_2}/g\\ = hw{c_1} + \frac{(Bg)}{(c_1)} + \frac{B}{(hw)} \end{array} 显然，当B不变时，增大g会增大MAC 模型中的分支数量越少，模型的速度越快 element-wise操作对速度影响非常大。 网络设计论文做了一个简单的操作，即通道分割，简单起见，假设分为两组，这里满足第三条原则；其中一组不做任何操作，满足第三条原则；一组进行深度可分离卷积，注意，这里保证输入输出通道不变，以满足第一条原则；组合的时候使用通道的组合，而不是相加，满足第四条原则。与shufflenetv1相比，下采样的操作多了一个1*1的卷积来混合特征。]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文阅读-CBAM: Convolutional Block Attention Module]]></title>
    <url>%2F2018%2F12%2F02%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-CBAM-Convolutional-Block-Attention-Module%2F</url>
    <content type="text"><![CDATA[研究问题：在给定特征图下，通过通道和空间两个维度推导出注意力图，然后将注意力图乘到输入的特征图上以用来自适应的细化输入的特征。设计的CBAM是一个轻量的模块，可以方便的集成在任意的CNN模型中。 相关信息：1、VGGNet通过堆积相同的形状的块并不会使得结果变差；ResNet使用了跳跃连接与相同的拓扑残差块构建了非常深的网络；GoogleNet表明增加网络的宽度可以改善网络的性能；Xception和ResNeXt表明基数比深度与宽度这两个因素具有更强的表示能力。 2、注意力机制不仅可以将注意力集中在感兴趣的区域，还能够提高感兴趣区域的表现力。论文的目的就在于利用注意力机制，关注重要的特征并抑制不重要的特征。 3、卷积操作本质是通过跨通道与空间来提取特征，所以论文就分别设计了通道与空间两个注意力模块。 网络架构：1、分为两个子模块，一个是通道注意力模块，一个是空间注意力模块。具体原理如下：给定一个特征图$F \in {\mathbb{R}^{C \times H \times W}}$，生成的通道注意力图为${M_c} \in {\mathbb{R}^{C \times 1 \times 1}}$，空间注意力图为${M_s} \in {\mathbb{R}^{1 \times H \times W}}$，对注意力过程总结如下： \begin{array}{c} {M_c}(F) = \sigma (MLP(AvgPool(F)) + MLP(MaxPool(F)))\\ = \sigma ({W_1}({W_0}(F_{avg}^c)) + {W_1}({W_0}(F_{\max }^c))) \end{array}概括来说，就是输入特征图依次与通道注意力图与空间注意力图作点乘，最终得到更加细化的特征图。 2、1）通道注意力模块： 通道注意力图主要是由通道之间的关系得到，过去人们常用平均池化来聚合空间信息，但论文认为最大池化或许能捕获到另外一些重要的特征，所以论文同时使用了平均池化与最大池化。为了降低运算量，首先对特征图的空间维度进行了压缩，之后并行的两种池化操作，将结果输入到一个多层感知机中，最后将结果对应元素相加即得到通道注意力图，公式表示如下： 2）空间注意力模块 通道注意力关注的是目标是什么，而空间注意力则关注的是目标在哪，二者可以相互补充。论文在通道轴上使用了最大池化与平均池化并将其结合起来，之后通过一个标准的卷积操作，得到空间注意力图。其用公式总结如下： 3、经过试验验证，模块插入方式如下：]]></content>
      <categories>
        <category>论文</category>
      </categories>
  </entry>
</search>
