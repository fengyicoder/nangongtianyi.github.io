---
title: >-
  论文阅读-Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image
  Segmentation
date: 2019-03-24 11:06:59
tags:
categories:
    - 论文
mathjax: true
---


## 研究目标
神经架构搜索的网络已经在图像任务中取得了比人类设计的网络更好的成绩，由此，作者提出将神经架构搜索应用到语义分割领域，来获取较优的分割结果。
<!-- more -->
## 亮点：
1、 提出了网络级架构搜索空间来联合单元级架构搜索空间进行搜索，寻找更优的结构。

2、开发出了一个可微的连续公式，可以在两级分层架构上进行有效的搜索。
## 相关信息：
1、神经架构搜索旨在自动设计网络结构，从而减少人工的时间与工作量。早期的工作大都试图直接建立整个网络，后来转向搜索可重复单元（例如resnet块），外部网络级结构则通过人类设计，即控制分层计算的内部单元级使用自动搜索，而控制分辨率的网络级则使用手动设计。

2、神经架构搜索在图像分类任务上取得了较大的成功，但直接应用在语义分割任务上则效果不佳，原因是NAS一般使用从低分辨率到高分辨率的迁移学习，而语义分割是密集型的预测任务，需要直接在高分辨率图像上进行学习，这就需要设计一个更加松弛的搜索空间来捕捉高分辨率的变化，同时需要更加高效的搜索技术，因为需要更多的计算。
## 网络设计
1、单元级搜索空间：将一个小的全卷积模块定义为一个单元，一个单元是由B个块组成的有向无环图。每个块是双分支结构，单元$l$中的块$i$通常用一个5元组表示$({I_1},{I_2},{O_1},{O_2},C)$,其中$I_1$与$I_2$是输入张量的选择，$O_1$与$O_2$是输出张量的选择，$C$是组合两个分支的方法。单元的输出张量$H^l$是所有块输出张量$\{ H_1^l, \ldots ,H_B^l\} $的组合。可能的输入张量是由前两个单元的输出以及当前单元当前块之前的输出组成。可能的层类型O为：
 1）$3 \times 3$深度分离卷积
 2）$5 \times 5$深度分离卷积
 3）$3 \times 3$空洞卷积，空洞率为2
 4）$5 \times 5$空洞卷积，空洞率为2
 5）$3 \times 3$的平均池化
 6）$3 \times 3$的最大池化
 7）跳跃连接
 8）无连接
对于可能的组合操作$C$的集合，采用简单的对应元素相加的方法。
由于以上给出的都是离散的方式，搜索空间较大，为了方便用梯度下降法求解，需要转换成连续空间的搜索。这里所作的操作是对两个分支分别加权:
$$H_i^l = {\alpha ^1}*{O_1}({I_1}) + {\alpha ^2}*{O_2}({I_2})$$
其中，${\alpha ^1} + {\alpha ^2} = 1$

2、网络级搜素空间：所谓的网络级搜索空间，其实就是特征图分辨率改变步骤的选择，在由于密集图像预测的各种网络中，一般有如下的原则：
1）下一层的空间分辨率要么是两倍大，要么是两倍小，要么保持不变
2）最小的空间分辨率是原图像分辨率的下采样32倍
3）开始第一层的特征图一般是原来的四倍小
网络级搜索空间示例如下：
![](/img/net.png)
为了建立连续松弛，每层$l$至多有四个隐藏状态$\ {}^4{H^l},{}^8{H^l},{}^{16}{H^l},{}^{32}{H^l}\ $，左上标表示空间分辨率，分辨率可能从三个地方进行转移，分别是分辨率是其一半的地方，分辨率相同的地方以及分辨率是其两倍的地方，分别给于三个$\beta $权重，且其和为1，所以我们可以将其视为转移概率，而要找到一条最大概率的路径可以通过维特比算法达成。
