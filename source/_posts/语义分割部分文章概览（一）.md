---
title: 语义分割部分文章概览（一）
date: 2018-12-19 09:05:58
tags:
categories:
    - 论文
---

此部分是关于部分语义分割论文的大致浏览
<!-- more -->

## 一、<font face="Time New Roman" >The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation</font>

论文主要是利用了DenseNet杰出的性能，将其应用到了语义分割的任务之中，并对网络的结构做了细微的调整，使其更容易训练，最终达到了较好的分割结果。如图所示：
![Fully Convolution DenseNets](/img/t.png)
为了更好的进行上采样，仅在Densenet层之后进行跨层连接，减小训练的难度。

## 二、<font face="Time New Roman" >DenseASPP for Semantic Segmentation in Street Scenes</font>

论文认为，对于较大分辨率的图片，获取更大的感受野与提取多尺度信息是两个比较重要的问题。为了同时解决这两个问题，论文在ASPP（空洞金字塔池化）上做了改动，使用了一种密集连接的方式（个人认为参考了Densenet网络），实现了较好的分割效果。
![DenseASPP](/img/DenseASPP.png)
通过这样一种串行的方式，的确取得了远大于ASPP的感受野，同时实现了多尺度的提取。

## 三、<font face="Time New Roman" >BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</font>

论文研究了如何在不牺牲精度跟分辨率的前提下保证较高的实时分割效率。网络结构如下所示：
![Bilateral Segmentation Network](/img/Bilateral.png)
为了保证在语义分割中比较重要的空间分辨率与感受野，论文设计了两条路径，一条是空间路径，由三层卷积组成，目的是取得分辨率较高的1/8特征图；一条是语义路径，使用了一种轻量化模型Xception来快速增加感受野，同时做了一个最大池化操作使得感受野最大化。为了融合两部分的特征图，论文提出了一个特征融合模块与注意力优化模块。同时，为了辅助训练，在主损失函数之外还增加了两个辅助损失函数进行辅助训练。

## 四、<font face="Time New Roman" >ICNet for Real-Time Semantic Segmentation on High-Resolution Images</font>

### 问题的引入与介绍

论文使用了多分辨率分支与标签引导来处理实时语义分割的问题，利用了PSPnet网络的基础框架，虽然略微牺牲了网络的分割精度，但大大缩短了网络推理的速度。
论文主要有三个贡献：
1. 提出了一种创新的图像级联网络，利用了低分辨率的语义信息与高分辨率的细节信息来进行语义分割。
2. 提出的级联特征融合单元与级联标签导向来细化分割结果。
3. ICNet实现了5倍的加速，降低了5倍的内存。

### 网络设计

1. 通过分析，计算复杂度与空间分辨率有较大关系，随着空间分辨率的提高，计算复杂度成平方的形式增加
2. 直觉上来说，下采样输入、缩小特征图与模型压缩可以提升分割速度，实际上也确实如此，但这样会导致分割结果惨不忍睹。
3. 所以作者设计了一种图像级联网络，语义分割的推理阶段最为耗费时间，所以这里使用了低分辨率的图片，使用的网络是经典分割网络；为了细化分割结果，又使用了较高分辨率的图片来补充信息，这里使用的是较为轻量化的网络。网络结构如下所示：
![ICNet](/img/ICNet.png)
4. 特征融合单元：融合单元如下图所示
![融合单元](/img/cff.png)
这里F1经过上采样之后还进行了空洞卷积，是为了融合近邻的语义。
5. 级联标签引导：对groundtruth进行不同的下采样，以引导不同分支的训练，这样损失函数就有三项。在测试阶段，抛弃低分辨率与中分辨率的两支，只使用高分辨率的支路。
6. 模型压缩：论文采用的压缩策略是一种渐进式的压缩，即先压缩部分，进行微调，再进行压缩，最终实现完全的压缩。
