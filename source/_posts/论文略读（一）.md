---
title: 论文略读（一）
date: 2021-01-22 20:24:36
tags:
categories:
    - 论文
mathjax: true
---

# DiCENet: Dimension-wise convolutions for efficient networks

## 主题

文章提出了一种分维度卷积之后维度特征融合的一种新模块，相对于经典的深度可分离模块（典型网络为MobileNet、ShuffleNet）来说性能更好，消耗资源更少。

<!-- more -->

## 相关信息

CNN的核心是卷积层，但卷积的进行会消耗大量的计算资源，因此出现了许多量化压缩的方法。flattened convolution通过对长宽通道三个维度依次卷积来近似标准卷积，但忽略了各维度之间的关系，因此无法在各种计算机视觉任务中推广；深度可分离卷积将卷积分解成立深度和点卷积，提高了效率，被诸多典型的网络所应用。

此外，神经架构搜索也是近来新兴的寻找网络最优架构的方法。网络的量化、压缩与蒸馏也可以用来提高网络的效率，与文章所述方法存在正交性。

## 内容

网络架构如图所示：

![DiCE unit](/img/dice.png)

网络采用三条分支来分别对三个维度进行编码，深度采用卷积核为${k_D} \in \mathbb{R}^{1 \times n \times n}$，宽度采用卷积核为${k_W} \in {\mathbb{R}^{n \times n \times 1} }$，高度采用卷积核为${k_H} \in {\mathbb{R}^{n \times 1 \times n} }$，产生的特征图为：
$$
{Y_{Dim} } = \{ {Y_D},{Y_W},{Y_H}\}  \in {\mathbb {R}^{3D \times H \times W} }
$$
之后对三个维度的信息进行融合，这里分为两个步骤，分别是局部融合与全局融合。这里的局部融合将特征图看作$D$个组的张量，每组有三个维度的信息，因此使用了${k_g} \in {\mathbb{R}^{3 \times 1 \times 1} }$的卷积核，产生特征图${Y_G} \in {\mathbb{R}^{D \times H \times W} }$。由于是卷积核对$D$组特征图分别进行处理，因此这里看作是局部融合操作。全局融合则是分别学习特征图空间与深度两个维度的语义表示，之后将其融合，具体来说就是在空间上使用了${k_S} \in {\mathbb{R}^{1 \times n \times n} }$大小的卷积核学习空间语义；深度上收到了SE unit的启发，使用了两个全连接层来学习深度的语义信息，为了学习到非线性的语义关系，中间还使用了ReLU激活函数，最后，使用深度语义信息来给空间语义信息加权，完成了全局信息的融合。

# Refining activation downsampling with SoftPool Alexandros

## 主题

CNN使用池化来减小特征图的大小，池化操作能够在局部实现空间不变性，还能够增大感受野。本文提出了一种新型的快速有效的池化方法，与其他方法相比，该方法能够在下采用的过程中保留更多的信息。

## 相关信息

下采样已经被广泛应用在手动提取特征的方法中，例如bag-of-words和bag-of-features，在这些方法中，图像被视为局部块的集合，将其池化或编码成向量。

CNN中的池化方法主要有以下几种：

![CNN_pooling](E:\project\nangongtianyi.github.io\source\img\CNN_pooling.png)

- Average Pooling：区域平均值
- Max Pooling：区域最大值
- Stochastic Pooling：使用一个核区域内激活的概率加权抽样
- Mix Pooling：最大池化和平均池化的混合
- Power average Pooling：最大池化与平均池化的结合，采用学习参数$p$来控制两者的比重，当$p=1$时等于局部求和，当$p = \infty $，等于最大池化
- S3 Pooling：对原始feature map网格中的行和列进行随机采样
- Preserving Pooling：使用平均池化，同时使用高于平均值的值增强激活
- Local Importance Pooling：

# Puzzle-CAM: Improved localization via matching partial and full features

## 主题

弱监督的语义分割主要用来缩小图像级语义分割与像素级语义分割的差距，然而主流的模型往往基于CAMs生成伪标签来训练网络，但CAMs往往只关注图像特征最明显的部分。为了处理这个问题，本文提出了Puzzle-CAM网络，通过puzzle模块和两个正则项来可以最小化来自块的特征与整幅图像特征的差距，找到尽可能完整的对象。

## 内容

![](/img/cam_1.png)

如图一，作者发现由图像的分割块生成的cam跟原始图像生成的cam有着很大的不同，作者认为这是由于监督情况的不同导致的，原始图像生成的cam是对整幅图像的监督，而分割块的监督可以理解成更加细致的监督，为了方便理解可以极端化为对像素的监督，也就是完全监督的情况。然而，分割块的cam看起来不那么平滑，因此作者想到结合两者，通过重建了正则项来提供自我监督，网络架构如图二所示：

![](/img/cam_2.png)

由原始图像生成的cam只关注最显著的特征，而由分割块产生的cam关注部分区域则会有过度激活的情况出现，其没有太多的上下文信息。为了解决这个问题，作者提出Puzzle-CAM来匹配全局和局部特征。

定义$F$是特征提取器，而$\theta $是分类器，$A$是所有类别的CAM的集合。在经过图像分类的训练之后，利用分类器的$c$通道的权重（即$c$类别的权重）与得到的特征图$f=F(I)$得到类别$c$的CAM：
$$
{A_c} = \theta _c^Tf
$$
使用$A_c$的最大值进行正则化可得到CAM，通过连接$A_c$可得到所有类别的CAM，即$A$。

设图像分类的预测向量为$\hat Y = \sigma (G({A_c}))$，使用multi-label soft margin loss作为损失函数，定义：
$$
\begin{gathered}
  { {\hat Y}_t} = \left\{ {\begin{array}{*{20}{c} }
  {\hat Y}&{if{\text{ }}Y = 1} \\ 
  {1 - \hat Y}&{otherwise} 
\end{array}} \right. \hfill \\
  {\ell _{cls}}(\hat Y,Y) =  - \log ({Y_t}) \hfill \\ 
\end{gathered}
$$

定义使用原始图像$A^s$得到预测向量与使用分割块拼接而成的图像得到的预测向量$A^{re}$分别为${\hat Y^s}$与${\hat Y^{re} }$，则原始图像与分割块拼接而成的图像的分类损失各为：
$$
\begin{gathered}
  {\mathcal{L}_{cls} } = {\ell _{cls} }({ {\hat Y}^s},Y) \hfill \\
  {\mathcal{L}_{p - cls} } = {\ell _{cls} }({ {\hat Y}^{re} },Y) \hfill \\ 
\end{gathered}
$$
这两个损失函数用来改善分类效果，与此同时，还使用了一个重构损失函数，如下：
$$
{\mathcal{L}_{re} } = ||{A^s} - {A^{re} }|{|_1}
$$
最终的损失函数如下所示：
$$
\mathcal{L} = {\mathcal{L}_{cls} } + {\mathcal{L}_{p - cls} } + \alpha {\mathcal{L}_{re} }
$$
其中，$\alpha$是平衡不同损失的平衡因子。