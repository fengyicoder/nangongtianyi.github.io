---
title: 论文略读（一）
date: 2021-01-22 20:24:36
tags:
categories:
    - 论文
mathjax: true
---

# DiCENet: Dimension-wise convolutions for efficient networks

## 主题

文章提出了一种分维度卷积之后维度特征融合的一种新模块，相对于经典的深度可分离模块（典型网络为MobileNet、ShuffleNet）来说性能更好，消耗资源更少。

<!-- more -->

## 相关信息

CNN的核心是卷积层，但卷积的进行会消耗大量的计算资源，因此出现了许多量化压缩的方法。flattened convolution通过对长宽通道三个维度依次卷积来近似标准卷积，但忽略了各维度之间的关系，因此无法在各种计算机视觉任务中推广；深度可分离卷积将卷积分解成立深度和点卷积，提高了效率，被诸多典型的网络所应用。

此外，神经架构搜索也是近来新兴的寻找网络最优架构的方法。网络的量化、压缩与蒸馏也可以用来提高网络的效率，与文章所述方法存在正交性。

## 网络架构

网络架构如图所示：

![DiCE unit](/img/dice.png)

网络采用三条分支来分别对三个维度进行编码，深度采用卷积核为${k_D} \in \mathbb{R}^{1 \times n \times n}$，宽度采用卷积核为${k_W} \in {\mathbb{R}^{n \times n \times 1} }$，高度采用卷积核为${k_H} \in {\mathbb{R}^{n \times 1 \times n} }$，产生的特征图为：
$$
{Y_{Dim} } = \{ {Y_D},{Y_W},{Y_H}\}  \in {\mathbb {R}^{3D \times H \times W} }
$$
之后对三个维度的信息进行融合，这里分为两个步骤，分别是局部融合与全局融合。这里的局部融合将特征图看作$D$个组的张量，每组有三个维度的信息，因此使用了${k_g} \in {\mathbb{R}^{3 \times 1 \times 1} }$的卷积核，产生特征图${Y_G} \in {\mathbb{R}^{D \times H \times W} }$。由于是卷积核对$D$组特征图分别进行处理，因此这里看作是局部融合操作。全局融合则是分别学习特征图空间与深度两个维度的语义表示，之后将其融合，具体来说就是在空间上使用了${k_S} \in {\mathbb{R}^{1 \times n \times n} }$大小的卷积核学习空间语义；深度上收到了SE unit的启发，使用了两个全连接层来学习深度的语义信息，为了学习到非线性的语义关系，中间还使用了ReLU激活函数，最后，使用深度语义信息来给空间语义信息加权，完成了全局信息的融合。